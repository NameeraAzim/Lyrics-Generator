{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TWaSyTrLAKSp"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\caoki\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pandas) (2021.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\caoki\\appdata\\roaming\\python\\python37\\site-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pandas) (1.19.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\caoki\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\caoki\\AppData\\Local\\Programs\\Python\\Python37\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spotipy in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (2.19.0)Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spotipy) (1.26.7)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\caoki\\AppData\\Local\\Programs\\Python\\Python37\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: six>=1.15.0 in c:\\users\\caoki\\appdata\\roaming\\python\\python37\\site-packages (from spotipy) (1.15.0)\n",
            "Requirement already satisfied: requests>=2.25.0 in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spotipy) (2.26.0)\n",
            "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests>=2.25.0->spotipy) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests>=2.25.0->spotipy) (2.0.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests>=2.25.0->spotipy) (2021.10.8)\n",
            "Requirement already satisfied: bs4 in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from bs4) (4.11.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.2.post1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\caoki\\AppData\\Local\\Programs\\Python\\Python37\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (1.10.2+cu113)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from torch) (3.10.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\caoki\\AppData\\Local\\Programs\\Python\\Python37\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (4.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (1.19.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: requests in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (2.26.0)\n",
            "Requirement already satisfied: sacremoses in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (2021.10.23)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\caoki\\appdata\\roaming\\python\\python37\\site-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\caoki\\appdata\\roaming\\python\\python37\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->transformers) (1.26.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->transformers) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->transformers) (2.0.8)\n",
            "Requirement already satisfied: six in c:\\users\\caoki\\appdata\\roaming\\python\\python37\\site-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from sacremoses->transformers) (8.0.3)\n",
            "Requirement already satisfied: joblib in c:\\users\\caoki\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\users\\caoki\\appdata\\roaming\\python\\python37\\site-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\caoki\\AppData\\Local\\Programs\\Python\\Python37\\python.exe -m pip install --upgrade pip' command.\n",
            "UsageError: Line magic function `%` not found.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
        "import torch\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "import spotipy\n",
        "import pandas as pd\n",
        "%pip install pandas\n",
        "%pip install spotipy\n",
        "%pip install bs4\n",
        "%pip install torch\n",
        "%pip install transformers\n",
        "\n",
        "% matplotlib inline\n",
        "\n",
        "\n",
        "torch.manual_seed(413)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Er98e4xLDmLI"
      },
      "outputs": [],
      "source": [
        "cid = '5c2034b1ae67482c8e309a15b8301688'\n",
        "secret = '2012b40e3aad47c68743b538f92f378e'\n",
        "\n",
        "client_credentials_manager = SpotifyClientCredentials(\n",
        "    client_id=cid, client_secret=secret)\n",
        "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_BHmZ0mPFOR"
      },
      "source": [
        "# Retrieving the Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "53kyr8hHGqII"
      },
      "outputs": [],
      "source": [
        "# Helper functions\n",
        "\n",
        "# Getting artist and song titles\n",
        "def get_album_tracks(uri_info):\n",
        "    titles = []\n",
        "    artists = []\n",
        "    one = sp.playlist_tracks(uri_info, limit=100, offset=0, market='US')\n",
        "    df1 = pd.DataFrame(one)\n",
        "\n",
        "    for i, x in df1['items'].items():\n",
        "        track = x['track']\n",
        "        titles.append(track['name'])\n",
        "        artists.append(track['artists'][0]['name'])\n",
        "\n",
        "    df2 = pd.DataFrame({'title': titles, 'artist': artists})\n",
        "\n",
        "    return df2\n",
        "\n",
        "# Get lyrics using the Genius API\n",
        "\n",
        "\n",
        "def scrape_lyrics(artistname, songname):\n",
        "    artistname2 = str(artistname.replace(' ', '-')\n",
        "                      ) if ' ' in artistname else str(artistname)\n",
        "    songname2 = str(songname.replace(' ', '-')\n",
        "                    ) if ' ' in songname else str(songname)\n",
        "    page = requests.get('https://genius.com/' +\n",
        "                        artistname2 + '-' + songname2 + '-' + 'lyrics')\n",
        "    html = BeautifulSoup(page.text, 'html.parser')\n",
        "\n",
        "    lyrics1 = html.find(\"div\", class_=\"lyrics\")\n",
        "    lyrics2 = html.find(\"div\", class_=\"Lyrics__Container-sc-1ynbvzw-6 jYfhrf\")\n",
        "    if lyrics1:\n",
        "        lyrics = lyrics1.get_text()\n",
        "    elif lyrics2:\n",
        "        lyrics = lyrics2.get_text()\n",
        "    elif lyrics1 == lyrics2 == None:\n",
        "        lyrics = None\n",
        "\n",
        "    lines = []\n",
        "    for div in html.findAll('div', {'class': 'Lyrics__Container-sc-1ynbvzw-6 jYfhrf'}):\n",
        "        lines.extend([text if text[0] !=\n",
        "                      '[' else '\\n' for text in div.stripped_strings])\n",
        "\n",
        "    lyrics = \"\"\n",
        "    for line in lines:\n",
        "        if line != '\\n':\n",
        "            lyrics += line + '\\n'\n",
        "\n",
        "    return lyrics\n",
        "\n",
        "# Clean and format dataframe with artists, titles, and lyrics\n",
        "\n",
        "\n",
        "def format_data(tracks_data):\n",
        "    lyrics_data = []\n",
        "    for index, row in tracks_data.iterrows():\n",
        "        song = scrape_lyrics(row['artist'], row['title'])\n",
        "        if song != '':\n",
        "            lyrics_data.append(song)\n",
        "        elif song == '':\n",
        "            tracks_data = tracks_data.drop(index)\n",
        "\n",
        "    tracks_data = tracks_data.reset_index(drop=True)\n",
        "    lyrics_df = pd.DataFrame({\n",
        "        'lyrics': lyrics_data\n",
        "    })\n",
        "\n",
        "    result_df = tracks_data.merge(lyrics_df, left_index=True, right_index=True)\n",
        "\n",
        "    return result_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B3OOr6ikppb",
        "outputId": "82e5cf88-8897-4365-de47-0eb7fe022b42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 title          artist  \\\n",
            "0   I Knew I Loved You   Savage Garden   \n",
            "1        How Do I Live     LeAnn Rimes   \n",
            "2          Back At One  Brian McKnight   \n",
            "3  From This Moment On    Shania Twain   \n",
            "4            Sometimes  Britney Spears   \n",
            "\n",
            "                                              lyrics  \n",
            "0  Maybe it's intuition\\nBut some things you just...  \n",
            "1  How do I get through one night without you?\\nI...  \n",
            "2  It's undeniable\\nThat we should be together\\nI...  \n",
            "3  I do swear that I'll always be there\\nI'd give...  \n",
            "4  You tell me you're in love with me\\nLike you c...  \n"
          ]
        }
      ],
      "source": [
        "# Loading tracks from various love song playlists on Spotify\n",
        "tracks1 = get_album_tracks('spotify:playlist:37i9dQZF1DWXqpDKK4ed9O')\n",
        "data1 = format_data(tracks1)\n",
        "\n",
        "tracks2 = get_album_tracks('spotify:playlist:2dcBq49u1O05UfOYp7IliA')\n",
        "data2 = format_data(tracks2)\n",
        "\n",
        "tracks3 = get_album_tracks('spotify:playlist:1k1OMvzbPSRzG2Dt5kJXay')\n",
        "data3 = format_data(tracks3)\n",
        "\n",
        "tracks4 = get_album_tracks('spotify:playlist:37i9dQZF1DXc3KygMa1OE7')\n",
        "data4 = format_data(tracks4)\n",
        "\n",
        "frames = [data1, data2, data3, data4]\n",
        "\n",
        "df = pd.concat(frames)\n",
        "\n",
        "# Filter duplicate songs because we used multiple playlists\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Check\n",
        "print(df.head())\n",
        "lyrics_data = df['lyrics']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCOClSe9rikM"
      },
      "source": [
        "# GPT-2 Tokenizer\n",
        "\n",
        "I'm using the Huggingface transformers library on the lyrics data to fine-tune the GPT2 model in order to generate song lyrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8yWFP5HroyI",
        "outputId": "a2b90936-5072-4cbb-f6f1-53778b5d3e76"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "# Load GPT tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\n",
        "    'gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbuxA1BBXJl8",
        "outputId": "6972a6bf-a042-4fa5-fcde-b8fa56459b8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[  40, 1842,  428, 3644, 3783, 1398]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[   40,  1842, 37793]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Exploring the GPT2 tokenizer\n",
        "# GPT-2 cannot work with strings directly. We need to tokenize each string, turning it into a list of numbers/tokens instead\n",
        "test_sentence = \"I love this computer science class\"\n",
        "input_ids = tokenizer.encode(test_sentence, return_tensors='pt')\n",
        "\n",
        "test_sentence2 = \"I love puppies\"\n",
        "input_ids2 = tokenizer.encode(test_sentence2, return_tensors='pt')\n",
        "\n",
        "print(input_ids)\n",
        "input_ids2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySb1bkcw_q-g"
      },
      "source": [
        "# PyTorch Dataset and Dataloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbyCOZze_vjx",
        "outputId": "721ba708-357a-4560-a70d-ea689f15d2cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1255\n"
          ]
        }
      ],
      "source": [
        "# Keeping the batch size at 2 to avoid out of memory errors because GPT2 is a large model\n",
        "batch_size = 2\n",
        "\n",
        "# Lyrics will truncate without the eos token if it is longer than 1024 tokens\n",
        "max_length = max([len(tokenizer.encode(lyric))\n",
        "                  for lyric in lyrics_data])\n",
        "\n",
        "print(max_length)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "J6kkWGaRJ6TS"
      },
      "outputs": [],
      "source": [
        "# Custom dataset class with PyTorch\n",
        "class LyricsDataset(Dataset):\n",
        "\n",
        "    def __init__(self, lyrics_data, tokenizer, max_length=768):\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "\n",
        "        for lyrics in lyrics_data:\n",
        "            # Wrap each of the lyrics in bos and eos tokens\n",
        "            # Pad if less than max_length tokens and truncate without eos token if longer than max_length tokens\n",
        "            encodings_dict = tokenizer('<|startoftext|>' + lyrics + '<|endoftext|>',\n",
        "                                       truncation=True, max_length=max_length, padding=\"max_length\")\n",
        "\n",
        "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "            self.attn_masks.append(torch.tensor(\n",
        "                encodings_dict['attention_mask']))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attn_masks[idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8Eyz47STYOTf"
      },
      "outputs": [],
      "source": [
        "dataset = LyricsDataset(lyrics_data, tokenizer, max_length=768)\n",
        "\n",
        "# Selects batches randomly and trains with a batch size of 2\n",
        "train_dataloader = DataLoader(\n",
        "    dataset, sampler=RandomSampler(dataset), batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4VuNrh8aR-T"
      },
      "source": [
        "# Finetuning GPT-2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6JGckeKaWqn",
        "outputId": "2bbcd3b1-5cdc-4440-9908-0ac4547773ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Embedding(50259, 768)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load model\n",
        "configuration = GPT2Config.from_pretrained(\n",
        "    'gpt2', output_hidden_states=False)\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2', config=configuration)\n",
        "\n",
        "# Necessary because we've added new bos and eos tokens\n",
        "model.resize_token_embeddings(len(tokenizer))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uLrY8y-lceUY"
      },
      "outputs": [],
      "source": [
        "# Function to train\n",
        "def train(dataloader, model, epochs, learning_rate, warmup_steps, epsilon):\n",
        "\n",
        "    training_stats = []\n",
        "\n",
        "    total_steps = len(dataloader) * epochs\n",
        "\n",
        "    optimizer = AdamW(model.parameters(),\n",
        "                      lr=learning_rate,\n",
        "                      eps=epsilon\n",
        "                      )\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=warmup_steps,\n",
        "                                                num_training_steps=total_steps)\n",
        "\n",
        "    for epoch in range(0, epochs):\n",
        "\n",
        "        print(f'======== Epoch {epoch + 1} / {epochs} ========')\n",
        "\n",
        "        total_train_loss = 0\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        for step, batch in enumerate(dataloader):\n",
        "\n",
        "            b_input_ids = batch[0]\n",
        "            b_labels = batch[0]\n",
        "            b_masks = batch[1]\n",
        "\n",
        "            model.zero_grad()\n",
        "\n",
        "            outputs = model(b_input_ids,\n",
        "                            labels=b_labels,\n",
        "                            attention_mask=b_masks,\n",
        "                            token_type_ids=None\n",
        "                            )\n",
        "\n",
        "            loss = outputs[0]\n",
        "\n",
        "            batch_loss = loss.item()\n",
        "            total_train_loss += batch_loss\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "        # Average training loss across a single batch\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'Epoch': epoch + 1,\n",
        "                'Training Loss': avg_train_loss\n",
        "            }\n",
        "        )\n",
        "\n",
        "    return model, training_stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdPdwhWKk8j5",
        "outputId": "49e7dba9-3a41-4655-cf95-4f5ea2d17a48"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\caoki\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\transformers\\optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 10 ========\n",
            "Average training loss: 5.94\n",
            "======== Epoch 2 / 10 ========\n",
            "Average training loss: 1.25\n",
            "======== Epoch 3 / 10 ========\n",
            "Average training loss: 1.12\n",
            "======== Epoch 4 / 10 ========\n",
            "Average training loss: 1.04\n",
            "======== Epoch 5 / 10 ========\n",
            "Average training loss: 0.98\n",
            "======== Epoch 6 / 10 ========\n",
            "Average training loss: 0.93\n",
            "======== Epoch 7 / 10 ========\n",
            "Average training loss: 0.88\n",
            "======== Epoch 8 / 10 ========\n",
            "Average training loss: 0.84\n",
            "======== Epoch 9 / 10 ========\n",
            "Average training loss: 0.81\n",
            "======== Epoch 10 / 10 ========\n",
            "Average training loss: 0.79\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Epoch</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.936393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.247347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.121989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.041597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.976653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.926351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.882852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.844295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.811872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.790221</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss\n",
              "Epoch               \n",
              "1           5.936393\n",
              "2           1.247347\n",
              "3           1.121989\n",
              "4           1.041597\n",
              "5           0.976653\n",
              "6           0.926351\n",
              "7           0.882852\n",
              "8           0.844295\n",
              "9           0.811872\n",
              "10          0.790221"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model, training_stats = train(\n",
        "    train_dataloader, model, epochs=10, learning_rate=0.0005, warmup_steps=100, epsilon=1e-8)\n",
        "\n",
        "# Display average training loss for each epoch\n",
        "results = pd.DataFrame(training_stats)\n",
        "results = results.set_index('Epoch')\n",
        "results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhgklEQVR4nO3df5xdd13n8dd77vz+cZM0mSQzSZu0tLa9QSkYK1hloagPihV4qKtiRfThWnF9IKwoiKsCu67rsq6LLOLDQoEqBWSBsogLWwRsRbGYllJIU0p/JDRt0kzSJPMrmZ+f/eOcO7kzmSTz49459577fj4e9zHnnnvv+X5m0r6/53zPud+jiMDMzPKnJesCzMysNhzwZmY55YA3M8spB7yZWU454M3McsoBb2aWUw54m0fSZyW9ptrvbRSSrpP0bUmjkl6ZdT0rIekfJP27rOuw7DngcyANo/JjVtKpiuc3LWdbEXFDRNxW7fcuh6QXSTpY7e0u0X8C3h0RvRHxqdVuTNIHJU0u+Df6+urLrF+S/rOkb0ialvS2RV7/OUkHJI1J+pSkizIosyk44HMgDaPeiOgFvgP8eMW628vvk9SaXZUNYwewdyUfPM/f9x2V/0YR8ZyVl9cQHgHeBPzdwhck7QL+Eng1sAUYB96zptU1EQd8jpX3hCW9WdJh4AOSNkj6jKQhScfT5e0Vn5k7vJf0i5K+LOlP0vc+LumGFb73Ukl3SxqR9PeS/lzSh1bwO12dtntC0l5JL6947WWSHkzbeFLSb6XrN6W/5wlJz0j6R0ln/bcv6VHgMuBv0z3tDkmDkj6dfu4RSb9S8f63Sfq4pA9JGgZ+cZm/y05JIelmSU9JOlSuOX29Q9I709eeSpc7Kl5/haT7JQ1LelTSSys2v0PSP6V/izslbUo/05nWeyz9e/yrpC3LqftCIuK2iPgsMLLIyzcBfxsRd0fEKPD7wE9I6qtmDZZwwOffVuAikj3Tm0n+zT+QPr8EOAW8+zyf/37gW8Am4B3ArZK0gvd+GPgqsBF4G8ke3LJIagP+FrgT2Ay8Drhd0pXpW24FfjUi+oBnA19M178ROAj0k+w1/i5w1hwdEfEs5h8BTQAfTT87CPwU8EeSrq/42CuAjwPrgdtZmRcDVwA/CrxZ0g+n6/8j8HzgGuA5wLXA76V/i2uBvwJ+O237hcD+im3+HPBLJH+ndqDccbwGWAdcTPJv8VqS/wbOUtEpLvb4zAp/113A3BBVRDwKTALftcLt2Xk44PNvFnhrRExExKmIOBYRn4iI8YgYAf4L8G/O8/kDEfHeiJgBbgMGSEJyye+VdAnwfcAfRMRkRHwZ+PQKfpfnA73AH6fb+SLwGeBV6etTQElSMSKOR8R9FesHgB0RMRUR/xhLmIRJ0sXAdcCbI+J0RNwPvA/4hYq3fSUiPhURsxGxaFACv7UgHBeet3h7RIxFxDdIOt/y73MT8J8i4khEDAFv50zH+MvA+yPi82nbT0bEQxXb/EBEPJzW9DGSTqL8t9gIXB4RMxFxb0QML1Z0RNwYEevP8bjxvH+8c+sFTi5YdxLwHnwNOODzbygiTpefSOqW9JfpSa5h4G5gvaTCOT5/uLwQEePpYu8y3zsIPFOxDuCJZf4epNt5IiJmK9YdALalyz8JvAw4IOkuSS9I1/93knHhOyU9Jul3ltHeM2lHuFh7sLTf408WhOPCK48qt3Egbbfc/oFzvHYx8Oh52jxcsTzOmX+zvwb+H/DRdNjnHemR0VoZBYoL1hVZfDjHVskBn38L91TfCFwJfH9EFEkO7QHONexSDYeAiyR1V6y7eAXbeQq4eMH4+SXAkwAR8a8R8QqSYYlPkey5EhEjEfHGiLgMeDnwm5JessT2LlowPjzXXqoa07FW/i0uSdstt7/jHK89ATxruQ2lRzBvj4gS8APAjcw/Ipmj5DLY0XM8PrvctlN7SYabym1cBnQAD69we3YeDvjm00cy5npCyeVpb611gxFxANgDvE1Se7pn/eMX+lx6QnDuQTKGPw68SVKbpBel2/lout2bJK2LiClgmGR4Ckk3Sro8PR9wEpgpv3aBup8A/hn4r2kN30MyNLLsk8MX8PvpkdUuknHzv0nXfwT4PUn96UnSP6ho+1bglyS9RFKLpG2SrrpQQ5JeLOm70yO2YZIhm0X/FullsL3neNyw2GfSNtrSf68WoDX925WPEG8HflzSD0nqIbks9ZMLjpKsShzwzeedQBdwFPgX4HNr1O5NwAuAY8AfkoTYxHnev42kI6p8XEwS6DeQ1P8e4Bcqxp5fDexPh55em7YJyQnMvycZHvgK8J6I+NIS634VsJNkz/kOkvMZf7/Ez5a9acHe79EFr99FMoT0BZLhnDvT9X9I0jE+AHwDuC9dR0R8laQz+J8kndZdzN/bP5etJCeFh4F96ef+epm/z4W8l+Tf61UkJ4pPkZ47iIi9JP82twNHSHY4/n2V27eUfMMPy4KkvwEeioiaH0HUK0k7gceBtoiYzrgcyyHvwduakPR9kp6VDie8lOTywk9lXJZZrvmbjbZWtgKfJLlE7yDwaxHxtWxLMss3D9GYmeWUh2jMzHKqroZoNm3aFDt37sy6DDOzhnHvvfcejYj+xV6rq4DfuXMne/bsyboMM7OGIenAuV7zEI2ZWU454M3McsoBb2aWUzUNeEnrldwQ4SFJ+ypm9zMzsxqr9UnWPwM+FxE/Jakd6L7QB8zMrDpqFvCS1pFMRfuLABExSXLnFjMzWwO1HKK5FBgiuQ/o1yS9L50edB4l96PcI2nP0NBQDcsxM2sutQz4VuB5wF9ExHOBMeCsO+lExC0RsTsidvf3L3qt/nlNzczynn94hLsfdudgZlaplgF/EDgYEfekzz9OEvhV1doi3nv3Y3z2m4eqvWkzs4ZWs4CPiMPAExV3vH8J8GC125FEabDIg08tet9gM7OmVevr4F8H3C7pAZK7uv9RLRopDRR56PAI0zMXvAubmVnTqOllkhFxP7C7lm0AlAaLTEzP8vjRMa7Y0nfhD5iZNYFcfJO1NLAOgAcPeZjGzKwsFwF/WX8P7a0tHoc3M6uQi4BvK7Rw5ZY+78GbmVXIRcBDcqL1waeG8S0IzcwS+Qn4wSLHxiZ5engi61LMzOpCrgIe4MFDJzOuxMysPuQm4K/amlwe6ROtZmaJ3AR8X2cbOzZ2+0SrmVkqNwEPZ060mplZDgN+/7FxRiemsy7FzCxzuQr4XduSE60PeZjGzCxfAe8pC8zMzshVwG8pdnBRT7vH4c3MyFnAS0pOtHoP3swsXwEPyReePDe8mVkeA36gyOT0LI8dHcu6FDOzTOUv4MtTFngc3syaXO4C/rJN6dzwHoc3syaXu4BvLbRw1dY+9j7lScfMrLnlLuDBc8ObmUFeA36wyPHxKQ4Pn866FDOzzOQz4Ad8otXMLJcBf5UD3swsnwHf29HKTs8Nb2ZNLpcBD8k4vAPezJpZbgN+1+A6DhwbZ+T0VNalmJllIrcBXz7R+tDhkYwrMTPLRn4D3lMWmFmTy23Ab+7rYKPnhjezJtZay41L2g+MADPAdETsrmV7C9r2iVYza2prsQf/4oi4Zi3Dvaw0UORbT48w5bnhzawJ5XaIBpJx+MnpWR4b8tzwZtZ8ah3wAdwp6V5JNy/2Bkk3S9ojac/Q0FBVG5+bsuCQZ5Y0s+ZT64D/wYh4HnAD8OuSXrjwDRFxS0Tsjojd/f39VW380k09dLS2sPdJj8ObWfOpacBHxJPpzyPAHcC1tWxvofLc8D7RambNqGYBL6lHUl95GfhR4Ju1au9cylfSeG54M2s2tdyD3wJ8WdLXga8CfxcRn6the4sqDRQ5MT7FoZOeG97MmkvNroOPiMeA59Rq+0tV+Y3WwfVdGVdjZrZ2cn2ZJMCVW4tIeBzezJpO7gM+mRu+x1MWmFnTyX3Ag+eGN7Pm1BwBP1DkO8+MM+y54c2siTRHwKcnWh865Lnhzax5NEXA75q7CbenLDCz5tEUAd/f18Gm3naPw5tZU2mKgJfE1QM+0WpmzaUpAh6ScfiHD496bngzaxrNE/ADRSZnZnnkyGjWpZiZrYmmCfhdvgm3mTWZpgn4Szf10tnW4nF4M2saTRPwhRZx5dai9+DNrGk0TcBDMg7vueHNrFk0V8APFjl5aoqnPDe8mTWB5gr4AZ9oNbPm0VQBf9XWvmRueAe8mTWBpgr4no5WLt3Uw4OHPCeNmeVfUwU8nDnRamaWd80X8INFnnjmFCdPeW54M8u35gv4gfLc8N6LN7N8a76AL09Z4IA3s5xruoDf3NfJpt4OX0ljZrnXdAEPvgm3mTWH5gz4gSIPPz3C5LTnhjez/GrOgB8sMjUTnhvezHKtOQN+wCdazSz/mjLgL93Uk8wN7xOtZpZjTRnwhRZx1daipywws1yrecBLKkj6mqTP1Lqt5SgNJjf/8NzwZpZXa7EH/3pg3xq0syylgSLDp6d58sSprEsxM6uJmga8pO3AjwHvq2U7K1HyTbjNLOdqvQf/TuBNQN1dcH711iIt8pU0ZpZfNQt4STcCRyLi3gu872ZJeyTtGRoaqlU5Z+lqLyRzw3sP3sxyqpZ78NcBL5e0H/gocL2kDy18U0TcEhG7I2J3f39/Dcs5W2lwnffgzSy3ahbwEfGWiNgeETuBnwW+GBE/X6v2VqI0UOTgcc8Nb2b51JTXwZeVT7Tu8168meXQmgR8RPxDRNy4Fm0tx9yUBR6HN7Mcauo9+P6+Dvr7OtjrgDezHGrqgAffhNvM8ssBP1jkkSOeG97M8scBP5DMDf/tIyNZl2JmVlUOeE9ZYGY51fQBv3NjD11tBY/Dm1nuNH3AF1rEVQN93oM3s9xp+oCHM1fSeG54M8sTBzzJOPzI6WkOHvfc8GaWHw54YNfgOsBTB5tZvjjggSu39CVzw3sc3sxyZEkBL6lHUku6/F2SXi6prbalrZ2u9gKX9fd6D97McmWpe/B3A52StgF3Aq8GPlirorJQGih6D97McmWpAa+IGAd+AnhPRPxbYFftylp7pcEiT544xclxzw1vZvmw5ICX9ALgJuDv0nWF2pSUjbmpgz1MY2Y5sdSAfwPwFuCOiNgr6TLgSzWrKgNXpwG/96mTGVdiZlYdrUt5U0TcBdwFkJ5sPRoRv1HLwtZaf18Hm/s6vAdvZrmx1KtoPiypKKkH+CbwoKTfrm1pa6806BOtZpYfSx2iKUXEMPBK4LPApSRX0uRKaaDII0dGmZieyboUM7NVW2rAt6XXvb8S+HRETAG5m7ilNFhkejb49tOjWZdiZrZqSw34vwT2Az3A3ZJ2ALkby/CVNGaWJ0s9yfou4F0Vqw5IenFtSsrOjo09dLcXPA5vZrmw1JOs6yT9qaQ96eN/kOzN50qhRVy1tc978GaWC0sdonk/MAL8dPoYBj5Qq6KyVBossu8pzw1vZo1vqQH/rIh4a0Q8lj7eDlxWy8KysmtwHSMTnhvezBrfUgP+lKQfLD+RdB2QywQszX2j1cM0ZtbYlnSSFXgt8FeS1qXPjwOvqU1J2bpyazo3/KFhXvrsrVmXY2a2Yku9iubrwHMkFdPnw5LeADxQw9oy0dlW4Fn9vb6Sxswa3rLu6BQRw+k3WgF+swb11IXSYJF9vpLGzBrcam7Zp6pVUWdKA8nc8MfHJrMuxcxsxVYT8Oe9jlBSp6SvSvq6pL2S3r6KttZUaTA50eq9eDNrZOcdg5c0wuJBLqDrAtueAK6PiNF0HpsvS/psRPzLykpdO1dXTFnwA5dvyrgaM7OVOW/AR0TfSjccyTeFyrN2taWPhvj20KbeDrYUO3yi1cwa2mqGaC5IUkHS/cAR4PMRcc8i77m5PAXC0NBQLctZltJA0VMWmFlDq2nAR8RMRFwDbAeulfTsRd5zS0Tsjojd/f39tSxnWUqDydzwp6c8N7yZNaaaBnxZRJwguYfrS9eivWooDaxjejZ45IjnhjezxlSzgJfUL2l9utwF/AjwUK3aq7bylTQehzezRrXUqQpWYgC4TVKBpCP5WER8pobtVdWOi7qTueE9Dm9mDapmAR8RDwDPrdX2a62lRVw94Jtwm1njWpMx+Ea1azC5kmZ2tiGu7jQzm8cBfx6lgSKjnhvezBqUA/485k60HjqZcSVmZsvngD+P79rSR6FFHoc3s4bkgD+PZG74Hl9JY2YNyQF/AaWBom/fZ2YNyQF/AaXBIodOnuYZzw1vZg3GAX8BpYHkNrSeG97MGo0D/gKuHkhmTPaJVjNrNA74C9jY28HWYqdPtJpZw3HAL0Fp0FMWmFnjccAvQWmgyCNDnhvezBqLA34JSoNFZmaDbz/tueHNrHE44JegNOApC8ys8Tjgl+CSi7rp7Wj1OLyZNRQH/BIkc8P3+UoaM2soDvglKg0U2XdoxHPDm1nDcMAvUWkwmRv+iePjWZdiZrYkDvglKk9Z4HF4M2sUDvglumJLL4UWeWZJM2sYDvgl6mwrcHl/r0+0mlnDcMAvg6csMLNG4oBfhtJAkcPDpzk2OpF1KWZmF+SAX4byTbj3HRrJuBIzswtzwC/D1Z6ywMwaiAN+GS7qaWdgXafH4c2sITjgl6k0UPSVNGbWEBzwy1QaLPLo0JjnhjezuueAX6bSQDI3/MNP+0SrmdW3mgW8pIslfUnSg5L2Snp9rdpaS7sGPWWBmTWG1hpuexp4Y0TcJ6kPuFfS5yPiwRq2WXPbN3TR19HqcXgzq3s124OPiEMRcV+6PALsA7bVqr21kswN72+0mln9W5MxeEk7gecC9yzy2s2S9kjaMzQ0tBblrFppsMi+Q8OeG97M6lrNA15SL/AJ4A0RcdZub0TcEhG7I2J3f39/rcupitJAkbHJGb7zjOeGN7P6VdOAl9RGEu63R8Qna9nWWipPWeCpg82sntXyKhoBtwL7IuJPa9VOFi7f3EtrizxlgZnVtVruwV8HvBq4XtL96eNlNWxvzXS2Fbh8c69PtJpZXavZZZIR8WVAtdp+1koDRf7p0aNZl2Fmdk7+JusKlQaLPD08wVHPDW9mdcoBv0KlgfLc8B6mMbP65IBfobm54T0Ob2Z1ygG/Qht62hlc1+kpC8ysbjngV8E34TazeuaAX4XSQJFHh0Y9N7yZ1SUH/CqUBtcxG/Ctw54b3szqjwN+FXYNlm/C7WEaM6s/DvhVmJsb3uPwZlaHHPCrIImrB30TbjOrTw74VSoNJHPDz3hueDOrMw74VSoNFhmfnOHAsbGsSzEzm8cBv0rlKQs8TGNm9cYBv0pXbEnnhveJVjOrMw74VepoTeeG9x68mdUZB3wVeMoCM6tHDvgqKA0UOTIywdCI54Y3s/rhgK+C8k24PTe8mdUTB3wV+EoaM6tHDvgqWN/dzrb1XR6HN7O64oCvkqsHPGWBmdUXB3yV7Bos8tjQKKcmPTe8mdUHB3yVlAaLzAbc8bUn+c6xcaZnZrMuycyaXGvWBeTFNRevp73Qwu/e8Q0A2gri4g3d7NjYzc5NPezc2JP+7Gbb+i5aC+5bzay2HPBVsqXYyVfecj2PHBll/7Ex9h8b58CxMR4/Os49jz/DeMXQTWuLuPiiNPw3JqFf7gS2beiizeFvZlXggK+ijb0dbOzt4Psv2zhvfUQwNDLB/mPj7D86xv5jYxw4Ns7jR8f418efYWxB+G/f0MWOjT1cuqln3hHAdoe/mS2DA34NSGJzsZPNxU6uvfSiea9FBEOjE3OBfyDd+99/dIw9++eHf6Ey/Dd2z+sEtm/opr3V4W9mZzjgMyaJzX2dbO7r5Pt2nh3+R0cn06GedK//WNIJ3HfgOKMT03PvLbSIbeu72LExGfrZ3NdJf18Hm3o72NTbPrfc2VZY61/RzDLigK9jkujv66C/r4Pdi4T/sbHJuXH+yk7ggYOHOHlqatFt9nW20t+bhH0S+u0Vy+nPdH1HqzsDs0bmgG9QktK98w6+d8dFZ70+MT3DsdFJhkYmODqaPJLlSYbS5X2HhxkamWDk9PQiLUCxszUN+yT4+8/RKWzq7fDwkFkdqlnAS3o/cCNwJCKeXat2bHEdrQUG13cxuL7rgu89PTXDsbG0Mxip7AwmGBqd4OjIJPueGubukQlGJhbvDNZ1tc0bCip3AOu721jf1c6G7jbWd7ezoaeNDd3tHioyWwO13IP/IPBu4K9q2IZVQWdbgW3ru9i2xM5g3tHAWUcIE+x9KjkyGD1HZ5C02cKG7vYk9Lvb0uU21s8tV3QK6bpiVxuFFlXzVzfLtZoFfETcLWlnrbZv2ehsK7B9Q3LVzoWcnprhxPgUx8cnOT4+ycnxKY6nz0+MT3J8fGru577Dw5xIn8/G4tuTkiOFDd3t6c8FnUHP/M5iQ3d7erTQguSOwZpP5mPwkm4Gbga45JJLMq7GqqmzrcDWdQW2rutc8mdmZ4ORiem54J/rDMbOdAYnTiXLQ6MTPPz0KCfGJ+ddTrpQe6GF3s5W+tJHb0crfZ1tyfN0+czrbem61nRd8r7e9lZafPRgDSbzgI+IW4BbAHbv3n2OfTdrFi0tYl1XG+u62tix8cLvL5uYnllwhHCmQzh5aoqR01OMTkwzcnqa0dPTPPHMeLI8Mc3I6alzHjVU6u0odw7lDiAJ/2JFp3Hm9bazOpTejlYfTdiayjzgzaqho7XA5mKBzcWlHy2URQTjkzNzYT+cdgJJBzDFyOnpinVTcx3DyfFJDh5POoqR01OcnrrwBHOFFtHdXqCnvZWejgK9Ha10t7fS09FKb0eB7rQTKb/e05G81tNeSN/TSnd78rmejla62go+srBzcsBb05M0F6RbVtBBlE3NzM51DCNpx1DZSYxOTDM2Mc3YxEzyc/LM8sHj44xPJsujE9NMTC9tNlIJutsqOoKOcudR0Wm0z+8kejoKdLUlHUXyOLPclT73yex8qOVlkh8BXgRsknQQeGtE3Fqr9syy1lZoYUNPOxt62le9remZWcbSwB+fnGa03CmkHcPoxAzj6fPRiZn0PdNzRyJPD5+eWx5L1y9HR2vLXPh3zXUEFc/b0ucdrXS3nekYznpferRSXvYRx9qq5VU0r6rVts3yrrXQwrquFtZ1tVVle7OzwfjUzFzYj0+Wf85wqmK5vP7U3PP5646MnGZ84sz6U1MzTM0s79RZZ1tL0gG0Fehsa6GzrUBnW+Gcz7vaCnQssq5z7tFS8VohfX8LHa0+3+EhGrMm0NKiuZPE1TY5PZt0CFPzO4exyem55XInMlaxfHpqltNTM5yemuHUVNJhPDM2f93pqVlOTa3sLmkSdLYu3iF0tRfS1wq0FUR7awttheTRUbHc1iraCy1zr7cXWmhrbaG9oOT5op/T/Oetybr2wtp3OA54M1uV9tYk6NZRnaONhSKCielZJtKwPxP+yc+JtKOo7BBOz3ssXJc8PzE+xen0CGRqZpbJ6VkmZ2aZmpllaiaYWcqlVcvUtqBjaE87hM19nXzstS+oensOeDOra5Lm9r5r1YksZmY2Df40/KdmZpmajvnP53UMi3QUFa/NrU8/O5mum5qZpaejNlN3OODNzBZRaBGFlkJDz5vkKQDNzHLKAW9mllMOeDOznHLAm5nllAPezCynHPBmZjnlgDczyykHvJlZTimifu6xIWkIOLDCj28CjlaxnJWqhzrqoQZwHQu5jvnqoY56qAFWV8eOiOhf7IW6CvjVkLQnIna7jvqowXW4jkaoox5qqGUdHqIxM8spB7yZWU7lKeBvybqAVD3UUQ81gOtYyHXMVw911EMNUKM6cjMGb2Zm8+VpD97MzCo44M3McqrhA17S+yUdkfTNDGu4WNKXJD0oaa+k12dUR6ekr0r6elrH27Ooo6KegqSvSfpMhjXsl/QNSfdL2pNRDeslfVzSQ5L2Sar+vdkuXMOV6d+g/BiW9Ia1riOt5T+k/31+U9JHJHVmVMfr0xr2ruXfYrHMknSRpM9L+nb6c0M12mr4gAc+CLw04xqmgTdGRAl4PvDrkkoZ1DEBXB8RzwGuAV4q6fkZ1FH2emBfhu2XvTgirsnweuc/Az4XEVcBzyGDv0lEfCv9G1wDfC8wDtyx1nVI2gb8BrA7Ip4NFICfzaCOZwO/AlxL8m9yo6TL16j5D3J2Zv0O8IWIuAL4Qvp81Ro+4CPibuCZjGs4FBH3pcsjJP8Db8ugjoiI0fRpW/rI5Cy6pO3AjwHvy6L9eiFpHfBC4FaAiJiMiBOZFgUvAR6NiJV+a3y1WoEuSa1AN/BUBjVcDdwTEeMRMQ3cBfzEWjR8jsx6BXBbunwb8MpqtNXwAV9vJO0Engvck1H7BUn3A0eAz0dEJnUA7wTeBMxm1H5ZAHdKulfSzRm0fykwBHwgHa56n6SeDOqo9LPAR7JoOCKeBP4E+A5wCDgZEXdmUMo3gR+StFFSN/Ay4OIM6ijbEhGH0uXDwJZqbNQBX0WSeoFPAG+IiOEsaoiImfQwfDtwbXoouqYk3QgciYh717rtRfxgRDwPuIFk6OyFa9x+K/A84C8i4rnAGFU6/F4JSe3Ay4H/nVH7G0j2Vi8FBoEeST+/1nVExD7gvwF3Ap8D7gdm1rqOxURy7XpVjrwd8FUiqY0k3G+PiE9mXU86DPAlsjk/cR3wckn7gY8C10v6UAZ1lPcYiYgjJGPO165xCQeBgxVHUh8nCfys3ADcFxFPZ9T+DwOPR8RQREwBnwR+IItCIuLWiPjeiHghcBx4OIs6Uk9LGgBIfx6pxkYd8FUgSSRjrPsi4k8zrKNf0vp0uQv4EeChta4jIt4SEdsjYifJcMAXI2LN99Ik9UjqKy8DP0pyaL5mIuIw8ISkK9NVLwEeXMsaFngVGQ3PpL4DPF9Sd/r/zUvI6ES8pM3pz0tIxt8/nEUdqU8Dr0mXXwP8n2pstLUaG8mSpI8ALwI2SToIvDUibl3jMq4DXg18Ix3/BvjdiPi/a1zHAHCbpAJJ5/2xiMjsEsU6sAW4I8kRWoEPR8TnMqjjdcDt6fDIY8AvZVBDuZP7EeBXs2gfICLukfRx4D6Sq8++RnbTBXxC0kZgCvj1tTr5vVhmAX8MfEzSL5NMmf7TVWnLUxWYmeWTh2jMzHLKAW9mllMOeDOznHLAm5nllAPezCynHPDWVCTNLJhVsWrfKpW0M8tZTc0Wavjr4M2W6VQ6lYNZ7nkP3oy5eePfkc4d/9Xy1LHpXvkXJT0g6Qvptx6RtEXSHenc+1+XVP66fUHSe9M5xu9Mv1FslgkHvDWbrgVDND9T8drJiPhu4N0ks2EC/C/gtoj4HuB24F3p+ncBd6Vz7z8P2JuuvwL484jYBZwAfrKmv43ZefibrNZUJI1GRO8i6/eT3CzlsXTiuMMRsVHSUWAgIqbS9YciYpOkIWB7RExUbGMnyRTNV6TP3wy0RcQfrsGvZnYW78GbnRHnWF6OiYrlGXyeyzLkgDc742cqfn4lXf5nztxS7ibgH9PlLwC/BnM3WVm3VkWaLZX3LqzZdFXM+AnJvVLLl0pukPQAyV74q9J1ryO5G9Nvk9yZqTwT5OuBW9LZ/2ZIwv4QZnXEY/BmzI3B746Io1nXYlYtHqIxM8sp78GbmeWU9+DNzHLKAW9mllMOeDOznHLAm5nllAPezCyn/j9nqNWrtNA1ZwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot training loss\n",
        "plt.plot(results['Training Loss'])\n",
        "plt.title('Training Loss for Epochs = 10')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Let's Crank Some Tunes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_lyrics(prompt, top_p, top_k, num_return_sequences, max_length):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "\n",
        "    outputs = model.generate(generated, do_sample=True, top_k=top_k, max_length=max_length,\n",
        "                             top_p=top_p, num_return_sequences=num_return_sequences)\n",
        "\n",
        "    for i, output in enumerate(outputs):\n",
        "        print(\n",
        "            f\"======= Output {i+1}: ========\\n{tokenizer.decode(output, skip_special_tokens=True)}\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======= Output 1: ========\n",
            "There's no place like home\n",
            "And there's nothing to see, no one to hold\n",
            "You can breathe again, you can feel the touch of my skin\n",
            "Even the sweet, warm days fade away\n",
            "Thoughts of you stay\n",
            "And I still want you\n",
            "To hold on\n",
            "And make it real\n",
            "In my life, I'll be true to myself\n",
            "I'll never make it a question of my love\n",
            "You're everything I've dreamed of\n",
            "But now you're gone\n",
            "And my spirit is dead\n",
            "With no trace of hope\n",
            "And you can never see, no one to hold\n",
            "You can breathe again, you can feel the touch of my skin\n",
            "Even the sweet, warm days fade away\n",
            "Thoughts of you stay\n",
            "And I still want you\n",
            "To hold on\n",
            "And make it real\n",
            "In my life, I'll be true to myself\n",
            "I'll never make it a question of my love\n",
            "You're everything I've dreamed of\n",
            "But now you're gone\n",
            "And my spirit is dead\n",
            "With no trace of hope\n",
            "And you can never see, no one to hold\n",
            "You can breathe again, you can feel the touch of my skin\n",
            "Even the sweet, warm days fade away\n",
            "Thoughts of you stay\n",
            "And I still want you\n",
            "To hold on\n",
            "And make it real\n",
            "In my life, I'll be true to myself\n",
            "I'll never make it a question of my love\n",
            "You're everything I've dreamed of\n",
            "\n",
            "\n",
            "\n",
            "======= Output 2: ========\n",
            "If you want something, you have to give it to me\n",
            "You can't have a day without tomorrow\n",
            "And if you want everything, you have to give it to me\n",
            "I want everything from here on\n",
            "So here it is\n",
            "You got to give it to me\n",
            "But first...\n",
            "Tell me what you want\n",
            "And do not waste my time\n",
            "I need your love\n",
            "So now I need you\n",
            "Your love, you always mean\n",
            "And I need you more than ever\n",
            "You know, I just want to make you understand\n",
            "And I need you more than ever\n",
            "You know, I just need you more than ever\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "generate_lyrics(prompt=\"<|startoftext|>\", top_p=0.95, top_k=50,\n",
        "                num_return_sequences=2, max_length=300)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "GPT-2Lyrics.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
